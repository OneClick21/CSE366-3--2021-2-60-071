{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "# Node Class represents a state in the search tree.\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.state = state  # The current position of the agent in the grid.\n",
    "        self.parent = parent  # The node in the search tree that generated this node.\n",
    "        self.action = action  # The action taken to get to this state.\n",
    "        self.path_cost = path_cost  # Cost from the start node to this node.\n",
    "\n",
    "    # Comparison operator for priority queue.\n",
    "    def __lt__(self, other):\n",
    "        return self.path_cost < other.path_cost\n",
    "\n",
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self.elements = []\n",
    "\n",
    "    def empty(self):\n",
    "        return len(self.elements) == 0\n",
    "\n",
    "    def put(self, item, priority):\n",
    "        heapq.heappush(self.elements, (priority, item))\n",
    "\n",
    "    def get(self):\n",
    "        return heapq.heappop(self.elements)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points a and b.\n",
    "\n",
    "    Parameters:\n",
    "    - a: Tuple representing the x and y coordinates of point a (e.g., (x1, y1))\n",
    "    - b: Tuple representing the x and y coordinates of point b (e.g., (x2, y2))\n",
    "\n",
    "    Returns:\n",
    "    - The Manhattan distance between points a and b.\n",
    "    \"\"\"\n",
    "    (x1, y1) = a\n",
    "    (x2, y2) = b\n",
    "    return abs(x1 - x2) + abs(y1 - y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, grid, start, goal):\n",
    "        self.grid = grid  # The grid layout where 1 represents an obstacle and 0 is free space.\n",
    "        self.initial = start  # Starting position of the agent.\n",
    "        self.goal = goal  # Goal position the agent aims to reach.\n",
    "\n",
    "    # Returns the possible actions from a given state.\n",
    "    def actions(self, state):\n",
    "        possible_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "        x, y = state\n",
    "\n",
    "        # Remove impossible actions based on grid boundaries and obstacles.\n",
    "        if x == 0 or self.grid[x - 1][y] == 1:\n",
    "            possible_actions.remove('UP')\n",
    "        if x == len(self.grid) - 1 or self.grid[x + 1][y] == 1:\n",
    "            possible_actions.remove('DOWN')\n",
    "        if y == 0 or self.grid[x][y - 1] == 1:\n",
    "            possible_actions.remove('LEFT')\n",
    "        if y == len(self.grid[0]) - 1 or self.grid[x][y + 1] == 1:\n",
    "            possible_actions.remove('RIGHT')\n",
    "\n",
    "        return possible_actions\n",
    "\n",
    "    # Returns the state resulting from taking a given action at a given state.\n",
    "    def result(self, state, action):\n",
    "        x, y = state\n",
    "        if action == 'UP':\n",
    "            return (x - 1, y)\n",
    "        if action == 'DOWN':\n",
    "            return (x + 1, y)\n",
    "        if action == 'LEFT':\n",
    "            return (x, y - 1)\n",
    "        if action == 'RIGHT':\n",
    "            return (x, y + 1)\n",
    "\n",
    "    # Checks if the goal has been reached.\n",
    "    def is_goal(self, state):\n",
    "        return state == self.goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env  # The environment in which the agent operates.\n",
    "\n",
    "    # Performs BFS search to find a path from the initial state to the goal.\n",
    "    def bfs_search(self):\n",
    "        frontier = deque([Node(self.env.initial)])  # FIFO queue for BFS.\n",
    "        came_from = {self.env.initial: None}  # Tracks how we reached each node.\n",
    "\n",
    "        while frontier:\n",
    "            current_node = frontier.popleft()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                if new_state not in came_from:\n",
    "                    frontier.append(Node(new_state, current_node, action))\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "    \n",
    "    # This is a_star_search \n",
    "    def a_star_search(self):\n",
    "        # The start node is created with a path cost of 0.\n",
    "        start_node = Node(self.env.initial, path_cost=0)\n",
    "        frontier = PriorityQueue()\n",
    "        frontier.put(start_node, 0)  # Priority is f-cost, initially the heuristic cost from start to goal\n",
    "        came_from = {self.env.initial: None}  # Tracks the best path to a node\n",
    "        cost_so_far = {self.env.initial: 0}  # Tracks the g-cost (cost so far to reach a node)\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost + heuristic(new_state, self.env.goal)  # f-cost = g-cost + h-cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "    \n",
    "    # Performs Uniform Cost Search to find the lowest cost path from the initial state to the goal.\n",
    "    def uniform_cost_search(self):\n",
    "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
    "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
    "        came_from = {self.env.initial: None}\n",
    "        cost_so_far = {self.env.initial: 0}\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Reconstructs the path from start to goal by following the came_from links.\n",
    "    def reconstruct_path(self, came_from, current):\n",
    "        path = []\n",
    "        while current in came_from:\n",
    "            path.append(current)\n",
    "            current = came_from[current]\n",
    "        path.append(self.env.initial)  # Start is not included in the came_from map.\n",
    "        path.reverse()  # Reverse to get the path from start to goal.\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_grid_and_path(grid, path):\n",
    "    grid_array = np.array(grid)  # Convert grid to numpy array for easy plotting.\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(grid_array, cmap='Greys', alpha=0.3)  # Grid background.\n",
    "    start = path[0]\n",
    "    goal = path[-1]\n",
    "    ax.plot(start[1], start[0], 'bs', markersize=10)  # Start position in blue.\n",
    "    ax.plot(goal[1], goal[0], 'gs', markersize=10)  # Goal position in green.\n",
    "    xs, ys = zip(*path)  # Extract X and Y coordinates of the path.\n",
    "    ax.plot(ys, xs, 'r-', linewidth=2)  # Plot the path in red.\n",
    "    ax.set_xticks(np.arange(-.5, len(grid[0]), 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, len(grid), 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"b\", linestyle='-', linewidth=1)\n",
    "    ax.tick_params(which=\"minor\", size=0)\n",
    "    ax.tick_params(which=\"major\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the solution using Uniform Cost Search algorithm\n",
      "Solution Path: [(0, 0), (0, 0), (0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (4, 2), (5, 2), (5, 3), (6, 3), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (8, 9), (9, 9)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the solution using A* Search algorithm\n",
      "Solution Path: [(0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 6), (2, 6), (2, 7), (3, 7), (3, 8), (3, 9), (4, 9), (5, 9), (6, 9), (7, 9), (8, 9), (9, 9)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_random_grid(size, obstacle_probability):\n",
    "    return np.random.choice([0, 1], size=(size, size), p=[1-obstacle_probability, obstacle_probability])\n",
    "\n",
    "# Define the size of the grid and the probability of an obstacle in each cell\n",
    "grid_size = 10\n",
    "obstacle_probability = 0.2  # 20% chance of being an obstacle\n",
    "\n",
    "# Generate a random grid\n",
    "grid = generate_random_grid(grid_size, obstacle_probability)\n",
    "\n",
    "# Define start and goal positions\n",
    "start = (0, 0)\n",
    "goal = (grid_size - 1, grid_size - 1)\n",
    "\n",
    "# Ensure start and goal are not obstacles\n",
    "grid[start] = 0\n",
    "grid[goal] = 0\n",
    "\n",
    "# Create the environment and agent\n",
    "environment = Environment(grid, start, goal)\n",
    "agent = Agent(environment)\n",
    "\n",
    "# Solve the problem with the UCS algorithm\n",
    "print(\"This is the solution using Uniform Cost Search algorithm\")\n",
    "solution_path_ucs = agent.uniform_cost_search()\n",
    "print(\"Solution Path:\", solution_path_ucs)\n",
    "\n",
    "# Visualize the solution\n",
    "visualize_grid_and_path(grid, solution_path_ucs) \n",
    "\n",
    "# Solve the problem with the A* algorithm\n",
    "print(\"This is the solution using A* Search algorithm\")\n",
    "solution_path_a_star = agent.a_star_search()\n",
    "print(\"Solution Path:\", solution_path_a_star)\n",
    "\n",
    "# Visualize the solution\n",
    "visualize_grid_and_path(grid, solution_path_a_star)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
